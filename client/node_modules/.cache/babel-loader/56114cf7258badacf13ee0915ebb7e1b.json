{"ast":null,"code":"import { FILE_STATES, logger } from \"@rpldy/shared\";\nimport processBatchItems from \"./processBatchItems\";\nimport { getBatchDataFromItemId, getIsItemBatchReady, isNewBatchStarting, cancelBatchForItem, loadNewBatchForItem, isItemBelongsToBatch } from \"./batchHelpers\";\n\nvar getIsItemInActiveRequest = function (queue, itemId) {\n  return !!~queue.getState().activeIds // $FlowFixMe - no flat\n  .flat().indexOf(itemId);\n};\n\nvar getIsItemReady = function (item) {\n  return item.state === FILE_STATES.ADDED;\n};\n\nexport var findNextItemIndex = function (queue) {\n  var state = queue.getState(),\n      itemQueue = state.itemQueue,\n      items = state.items;\n  var index = 0,\n      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a \"ready\" batch\n\n  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !getIsItemBatchReady(queue, nextId) || !getIsItemReady(items[nextId]))) {\n    index += 1;\n    nextId = itemQueue[index];\n  }\n\n  return nextId ? index : -1;\n};\nexport var getNextIdGroup = function (queue) {\n  var itemQueue = queue.getState().itemQueue;\n  var nextItemIndex = findNextItemIndex(queue);\n  var nextId = itemQueue[nextItemIndex],\n      nextGroup;\n\n  if (nextId) {\n    var batchData = getBatchDataFromItemId(queue, nextId);\n    var batchId = batchData.batch.id,\n        groupMax = batchData.batchOptions.maxGroupSize || 0;\n\n    if (batchData.batchOptions.grouped && groupMax > 1) {\n      nextGroup = [];\n      var nextBelongsToSameBatch = true; //dont group files from different batches\n\n      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {\n        nextGroup.push(nextId);\n        nextId = itemQueue[nextItemIndex + nextGroup.length];\n        nextBelongsToSameBatch = nextId && isItemBelongsToBatch(queue, nextId, batchId);\n      }\n    } else {\n      nextGroup = [nextId];\n    }\n  }\n\n  return nextGroup;\n};\n\nvar processNext = function (queue) {\n  var ids = getNextIdGroup(queue);\n  var resultP = Promise.resolve();\n\n  if (ids) {\n    var currentCount = queue.getCurrentActiveCount(),\n        _queue$getOptions = queue.getOptions(),\n        _queue$getOptions$con = _queue$getOptions.concurrent,\n        concurrent = _queue$getOptions$con === void 0 ? 0 : _queue$getOptions$con,\n        _queue$getOptions$max = _queue$getOptions.maxConcurrent,\n        maxConcurrent = _queue$getOptions$max === void 0 ? 0 : _queue$getOptions$max;\n\n    if (!currentCount || concurrent && currentCount < maxConcurrent) {\n      logger.debugLog(\"uploader.processor: Processing next upload - \", {\n        ids: ids,\n        state: queue.getState(),\n        currentCount: currentCount\n      });\n      var cancelled = false;\n      var newBatchP = Promise.resolve(false);\n\n      if (isNewBatchStarting(queue, ids[0])) {\n        newBatchP = loadNewBatchForItem(queue, ids[0]).then(function (allowBatch) {\n          cancelled = !allowBatch;\n\n          if (cancelled) {\n            cancelBatchForItem(queue, ids[0]);\n            processNext(queue);\n          }\n\n          return cancelled;\n        });\n      }\n\n      resultP = newBatchP.then(function (cancelled) {\n        if (!cancelled) {\n          processBatchItems(queue, ids, processNext);\n        }\n      });\n    }\n  }\n\n  return resultP;\n};\n\nexport default processNext;","map":{"version":3,"sources":["C:/Users/lucki/Desktop/ClassCodeProjects/amtil-mc/node_modules/@rpldy/uploader/lib/esm/queue/processQueueNext.js"],"names":["FILE_STATES","logger","processBatchItems","getBatchDataFromItemId","getIsItemBatchReady","isNewBatchStarting","cancelBatchForItem","loadNewBatchForItem","isItemBelongsToBatch","getIsItemInActiveRequest","queue","itemId","getState","activeIds","flat","indexOf","getIsItemReady","item","state","ADDED","findNextItemIndex","itemQueue","items","index","nextId","getNextIdGroup","nextItemIndex","nextGroup","batchData","batchId","batch","id","groupMax","batchOptions","maxGroupSize","grouped","nextBelongsToSameBatch","length","push","processNext","ids","resultP","Promise","resolve","currentCount","getCurrentActiveCount","_queue$getOptions","getOptions","_queue$getOptions$con","concurrent","_queue$getOptions$max","maxConcurrent","debugLog","cancelled","newBatchP","then","allowBatch"],"mappings":"AAAA,SAASA,WAAT,EAAsBC,MAAtB,QAAoC,eAApC;AACA,OAAOC,iBAAP,MAA8B,qBAA9B;AACA,SAASC,sBAAT,EAAiCC,mBAAjC,EAAsDC,kBAAtD,EAA0EC,kBAA1E,EAA8FC,mBAA9F,EAAmHC,oBAAnH,QAA+I,gBAA/I;;AAEA,IAAIC,wBAAwB,GAAG,UAAUC,KAAV,EAAiBC,MAAjB,EAAyB;AACtD,SAAO,CAAC,CAAC,CAACD,KAAK,CAACE,QAAN,GAAiBC,SAAjB,CAA2B;AAA3B,GACTC,IADS,GACFC,OADE,CACMJ,MADN,CAAV;AAED,CAHD;;AAKA,IAAIK,cAAc,GAAG,UAAUC,IAAV,EAAgB;AACnC,SAAOA,IAAI,CAACC,KAAL,KAAelB,WAAW,CAACmB,KAAlC;AACD,CAFD;;AAIA,OAAO,IAAIC,iBAAiB,GAAG,UAAUV,KAAV,EAAiB;AAC9C,MAAIQ,KAAK,GAAGR,KAAK,CAACE,QAAN,EAAZ;AAAA,MACIS,SAAS,GAAGH,KAAK,CAACG,SADtB;AAAA,MAEIC,KAAK,GAAGJ,KAAK,CAACI,KAFlB;AAGA,MAAIC,KAAK,GAAG,CAAZ;AAAA,MACIC,MAAM,GAAGH,SAAS,CAACE,KAAD,CADtB,CAJ8C,CAKf;;AAE/B,SAAOC,MAAM,KAAKf,wBAAwB,CAACC,KAAD,EAAQc,MAAR,CAAxB,IAA2C,CAACpB,mBAAmB,CAACM,KAAD,EAAQc,MAAR,CAA/D,IAAkF,CAACR,cAAc,CAACM,KAAK,CAACE,MAAD,CAAN,CAAtG,CAAb,EAAqI;AACnID,IAAAA,KAAK,IAAI,CAAT;AACAC,IAAAA,MAAM,GAAGH,SAAS,CAACE,KAAD,CAAlB;AACD;;AAED,SAAOC,MAAM,GAAGD,KAAH,GAAW,CAAC,CAAzB;AACD,CAbM;AAcP,OAAO,IAAIE,cAAc,GAAG,UAAUf,KAAV,EAAiB;AAC3C,MAAIW,SAAS,GAAGX,KAAK,CAACE,QAAN,GAAiBS,SAAjC;AACA,MAAIK,aAAa,GAAGN,iBAAiB,CAACV,KAAD,CAArC;AACA,MAAIc,MAAM,GAAGH,SAAS,CAACK,aAAD,CAAtB;AAAA,MACIC,SADJ;;AAGA,MAAIH,MAAJ,EAAY;AACV,QAAII,SAAS,GAAGzB,sBAAsB,CAACO,KAAD,EAAQc,MAAR,CAAtC;AACA,QAAIK,OAAO,GAAGD,SAAS,CAACE,KAAV,CAAgBC,EAA9B;AAAA,QACIC,QAAQ,GAAGJ,SAAS,CAACK,YAAV,CAAuBC,YAAvB,IAAuC,CADtD;;AAGA,QAAIN,SAAS,CAACK,YAAV,CAAuBE,OAAvB,IAAkCH,QAAQ,GAAG,CAAjD,EAAoD;AAClDL,MAAAA,SAAS,GAAG,EAAZ;AACA,UAAIS,sBAAsB,GAAG,IAA7B,CAFkD,CAEf;;AAEnC,aAAOT,SAAS,CAACU,MAAV,GAAmBL,QAAnB,IAA+BI,sBAAtC,EAA8D;AAC5DT,QAAAA,SAAS,CAACW,IAAV,CAAed,MAAf;AACAA,QAAAA,MAAM,GAAGH,SAAS,CAACK,aAAa,GAAGC,SAAS,CAACU,MAA3B,CAAlB;AACAD,QAAAA,sBAAsB,GAAGZ,MAAM,IAAIhB,oBAAoB,CAACE,KAAD,EAAQc,MAAR,EAAgBK,OAAhB,CAAvD;AACD;AACF,KATD,MASO;AACLF,MAAAA,SAAS,GAAG,CAACH,MAAD,CAAZ;AACD;AACF;;AAED,SAAOG,SAAP;AACD,CA1BM;;AA4BP,IAAIY,WAAW,GAAG,UAAU7B,KAAV,EAAiB;AACjC,MAAI8B,GAAG,GAAGf,cAAc,CAACf,KAAD,CAAxB;AACA,MAAI+B,OAAO,GAAGC,OAAO,CAACC,OAAR,EAAd;;AAEA,MAAIH,GAAJ,EAAS;AACP,QAAII,YAAY,GAAGlC,KAAK,CAACmC,qBAAN,EAAnB;AAAA,QACIC,iBAAiB,GAAGpC,KAAK,CAACqC,UAAN,EADxB;AAAA,QAEIC,qBAAqB,GAAGF,iBAAiB,CAACG,UAF9C;AAAA,QAGIA,UAAU,GAAGD,qBAAqB,KAAK,KAAK,CAA/B,GAAmC,CAAnC,GAAuCA,qBAHxD;AAAA,QAIIE,qBAAqB,GAAGJ,iBAAiB,CAACK,aAJ9C;AAAA,QAKIA,aAAa,GAAGD,qBAAqB,KAAK,KAAK,CAA/B,GAAmC,CAAnC,GAAuCA,qBAL3D;;AAOA,QAAI,CAACN,YAAD,IAAiBK,UAAU,IAAIL,YAAY,GAAGO,aAAlD,EAAiE;AAC/DlD,MAAAA,MAAM,CAACmD,QAAP,CAAgB,+CAAhB,EAAiE;AAC/DZ,QAAAA,GAAG,EAAEA,GAD0D;AAE/DtB,QAAAA,KAAK,EAAER,KAAK,CAACE,QAAN,EAFwD;AAG/DgC,QAAAA,YAAY,EAAEA;AAHiD,OAAjE;AAKA,UAAIS,SAAS,GAAG,KAAhB;AACA,UAAIC,SAAS,GAAGZ,OAAO,CAACC,OAAR,CAAgB,KAAhB,CAAhB;;AAEA,UAAItC,kBAAkB,CAACK,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAtB,EAAuC;AACrCc,QAAAA,SAAS,GAAG/C,mBAAmB,CAACG,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAnB,CAAmCe,IAAnC,CAAwC,UAAUC,UAAV,EAAsB;AACxEH,UAAAA,SAAS,GAAG,CAACG,UAAb;;AAEA,cAAIH,SAAJ,EAAe;AACb/C,YAAAA,kBAAkB,CAACI,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAlB;AACAD,YAAAA,WAAW,CAAC7B,KAAD,CAAX;AACD;;AAED,iBAAO2C,SAAP;AACD,SATW,CAAZ;AAUD;;AAEDZ,MAAAA,OAAO,GAAGa,SAAS,CAACC,IAAV,CAAe,UAAUF,SAAV,EAAqB;AAC5C,YAAI,CAACA,SAAL,EAAgB;AACdnD,UAAAA,iBAAiB,CAACQ,KAAD,EAAQ8B,GAAR,EAAaD,WAAb,CAAjB;AACD;AACF,OAJS,CAAV;AAKD;AACF;;AAED,SAAOE,OAAP;AACD,CA3CD;;AA6CA,eAAeF,WAAf","sourcesContent":["import { FILE_STATES, logger } from \"@rpldy/shared\";\nimport processBatchItems from \"./processBatchItems\";\nimport { getBatchDataFromItemId, getIsItemBatchReady, isNewBatchStarting, cancelBatchForItem, loadNewBatchForItem, isItemBelongsToBatch } from \"./batchHelpers\";\n\nvar getIsItemInActiveRequest = function (queue, itemId) {\n  return !!~queue.getState().activeIds // $FlowFixMe - no flat\n  .flat().indexOf(itemId);\n};\n\nvar getIsItemReady = function (item) {\n  return item.state === FILE_STATES.ADDED;\n};\n\nexport var findNextItemIndex = function (queue) {\n  var state = queue.getState(),\n      itemQueue = state.itemQueue,\n      items = state.items;\n  var index = 0,\n      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a \"ready\" batch\n\n  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !getIsItemBatchReady(queue, nextId) || !getIsItemReady(items[nextId]))) {\n    index += 1;\n    nextId = itemQueue[index];\n  }\n\n  return nextId ? index : -1;\n};\nexport var getNextIdGroup = function (queue) {\n  var itemQueue = queue.getState().itemQueue;\n  var nextItemIndex = findNextItemIndex(queue);\n  var nextId = itemQueue[nextItemIndex],\n      nextGroup;\n\n  if (nextId) {\n    var batchData = getBatchDataFromItemId(queue, nextId);\n    var batchId = batchData.batch.id,\n        groupMax = batchData.batchOptions.maxGroupSize || 0;\n\n    if (batchData.batchOptions.grouped && groupMax > 1) {\n      nextGroup = [];\n      var nextBelongsToSameBatch = true; //dont group files from different batches\n\n      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {\n        nextGroup.push(nextId);\n        nextId = itemQueue[nextItemIndex + nextGroup.length];\n        nextBelongsToSameBatch = nextId && isItemBelongsToBatch(queue, nextId, batchId);\n      }\n    } else {\n      nextGroup = [nextId];\n    }\n  }\n\n  return nextGroup;\n};\n\nvar processNext = function (queue) {\n  var ids = getNextIdGroup(queue);\n  var resultP = Promise.resolve();\n\n  if (ids) {\n    var currentCount = queue.getCurrentActiveCount(),\n        _queue$getOptions = queue.getOptions(),\n        _queue$getOptions$con = _queue$getOptions.concurrent,\n        concurrent = _queue$getOptions$con === void 0 ? 0 : _queue$getOptions$con,\n        _queue$getOptions$max = _queue$getOptions.maxConcurrent,\n        maxConcurrent = _queue$getOptions$max === void 0 ? 0 : _queue$getOptions$max;\n\n    if (!currentCount || concurrent && currentCount < maxConcurrent) {\n      logger.debugLog(\"uploader.processor: Processing next upload - \", {\n        ids: ids,\n        state: queue.getState(),\n        currentCount: currentCount\n      });\n      var cancelled = false;\n      var newBatchP = Promise.resolve(false);\n\n      if (isNewBatchStarting(queue, ids[0])) {\n        newBatchP = loadNewBatchForItem(queue, ids[0]).then(function (allowBatch) {\n          cancelled = !allowBatch;\n\n          if (cancelled) {\n            cancelBatchForItem(queue, ids[0]);\n            processNext(queue);\n          }\n\n          return cancelled;\n        });\n      }\n\n      resultP = newBatchP.then(function (cancelled) {\n        if (!cancelled) {\n          processBatchItems(queue, ids, processNext);\n        }\n      });\n    }\n  }\n\n  return resultP;\n};\n\nexport default processNext;"]},"metadata":{},"sourceType":"module"}